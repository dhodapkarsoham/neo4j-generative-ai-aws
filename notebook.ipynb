{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3d39ab",
   "metadata": {
    "id": "3d3d39ab"
   },
   "source": [
    "# notebook.ipynb\n",
    "This is a sample notebook and web application which shows how Amazon Bedrock and Titan can be used with Neo4j. We will explore how to leverage generative AI to build and consume a knowledge graph in Neo4j.\n",
    "\n",
    "The dataset we're using is from the SEC's EDGAR system.  It was downloaded using [these scripts](https://github.com/neo4j-partners/neo4j-sec-edgar-form13).\n",
    "\n",
    "The dataflow in this demo consists of two parts:\n",
    "1. Ingestion - we read the EDGAR files with Bedrock, extracting entities and relationships from them.  Bedrock then generates Neo4j Cypher that is run against a Neo4j database deployed from AWS Marketplace.\n",
    "2. Consumption - A user inputs natural language into a web UI.  Bedrock converts that to Neo4j Cypher which is run against the database.  This flow allows non technical users to query the database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a9328-f17d-48ae-b72e-c333fb867eb0",
   "metadata": {
    "id": "f17a9328-f17d-48ae-b72e-c333fb867eb0",
    "tags": []
   },
   "source": [
    "## Setup\n",
    "Select the SageMaker Data Science 3.0 image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb2fda-70c8-4733-ac6f-2678e5cbff47",
   "metadata": {
    "id": "87eb2fda-70c8-4733-ac6f-2678e5cbff47"
   },
   "source": [
    "Now, let's install Bedrock libraries. Currently they are in preview. So, you have to download them here and unzip to a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be06b0f-fe29-417f-bc8c-0593eb908577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip uninstall -y botocore3\n",
    "#%pip uninstall -y boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a489800-9ba8-4584-af5f-a266ea14899d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -O /root/bedrock-python-sdk.zip https://preview.documentation.bedrock.aws.dev/Documentation/SDK/bedrock-python-sdk.zip\n",
    "!unzip /root/bedrock-python-sdk.zip -d /root/bedrock-python-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa6ceb0-bcaf-4122-8ab8-c39e682f1698",
   "metadata": {},
   "source": [
    "Make sure the `boto` & `botocore` libs correspond to the right version of your downloaded SDK. And then execute the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54d6af-36c1-4325-bae9-97786a49b003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install /root/bedrock-python-sdk/boto3-1.26.162-py3-none-any.whl\n",
    "%pip install /root/bedrock-python-sdk/botocore-1.29.162-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43720d2e-05cd-49de-bbb9-15c0b10d768b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --user \"langchain>=0.0.237\"\n",
    "%pip install --user nltk\n",
    "%pip install --user graphdatascience\n",
    "%pip install --user pydantic\n",
    "%pip install --user IProgress\n",
    "%pip install --user tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f91036-7018-465f-b4af-8d5523e7ed3a",
   "metadata": {},
   "source": [
    "Now restart the kernel.  That will allow the Python evironment to import the new packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad823ee-84ca-4de3-9b29-4b324ac5b9ae",
   "metadata": {
    "id": "4ad823ee-84ca-4de3-9b29-4b324ac5b9ae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Provide your `SERVICE_NAME` (e.g. `bedrock`) & `REGION_NAME` (e.g. `us-east-1`)\n",
    "SERVICE_NAME = 'bedrock'\n",
    "REGION_NAME = 'us-west-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5a70c-aee1-462b-953a-4c87a524a111",
   "metadata": {
    "id": "42c5a70c-aee1-462b-953a-4c87a524a111",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "bedrock = boto3.client(\n",
    " service_name=SERVICE_NAME,\n",
    " region_name=REGION_NAME,\n",
    " endpoint_url=f'https://{SERVICE_NAME}.{REGION_NAME}.amazonaws.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e43bb3c",
   "metadata": {
    "id": "4e43bb3c"
   },
   "source": [
    "## Prompt Definition\n",
    "In the upcoming sections, we will extract knowledge adhering to the following schema. This is a very Simplified schema to extract only the information we are interested in. Normally, you will have Domain Experts who come up with an ideal Schema. Neo4j being a schema-flexible database, the schema can be modified later to accomodate new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dfc155-d313-48e5-a5b0-17f6347beff5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Schema:\n",
    "````\n",
    "(:Company{ticker:string,name:string,sector:string})-[:FILED_ESG_REPORT]->(EsgReport{year:number,url:string})\n",
    "(:Company{ticker:string,name:string,sector:string})-[:PARTNERED_WITH{date:string,for:string}]->(:Company{ticker:string,name:string,sector:string})\n",
    "(:Company{ticker:string,name:string,sector:string})-[:DONATED_TO{amount:string,for:string}]->(:Charity{name:string})\n",
    "(:Company{ticker:string,name:string,sector:string})-[:HAS_ENV_METRIC]->(Metric{name:string,value:string})\n",
    "(:Company{ticker:string,name:string,sector:string})-[:HAS_SOCIAL_METRIC]->(Metric{name:string,value:string})\n",
    "(:Company{ticker:string,name:string,sector:string})-[:HAS_GOVERNANCE_METRIC]->(Metric{name:string,value:string})\n",
    "(:Company{ticker:string,name:string,sector:string})-[:HAS_GOAL]->(:Goal{target:string})\n",
    "(:Goal{name:string})-[:IS_ABOUT]->(:Criteria{name:string})\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7781a12b",
   "metadata": {
    "id": "7781a12b"
   },
   "source": [
    "To achieve our Extraction goal as per the schema, I am going to chain a series of prompts, each focused on only one task - to extract a specific entity. By this way, you can go for more granular extraction. The prompts I used here can be improved and in production scenario, you should consider running QA on the prompt pipelines to ensure that the extracted information is correct. Also, you should consider a landing and serving zones and ensure only curated data lands the serving zone.\n",
    "\n",
    "Let's go in this order to gather the data in accordance to out data model:\n",
    "1. Extract environmental, social and governance achievements\n",
    "2. Extract quantifiable criteria, value and target year for each goal\n",
    "3. Extract environmental metric and value from achievements\n",
    "4. Extract social metric and value from achievements\n",
    "5. Extract governance metric and value from achievements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7028d309",
   "metadata": {},
   "source": [
    "## Data Preparation and Helper functions\n",
    "Our input source is a `txt` file served from a URL. So, lets write some code to extract and convert the txt to json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27107c1c-a5f0-4c88-8bbd-e3ee94f758aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "inp_text = ''\n",
    "with open('./data/raw_2023-05-15_archives_edgar_data_1000097_0001000097-23-000006.txt') as f:\n",
    "    inp_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a414dc",
   "metadata": {},
   "source": [
    "Now, let's write some helper functions to call Bedrock's Tital model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d903cb98-ce84-43bb-b860-71a394604a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_titan_model(prompt):\n",
    "    try:\n",
    "        body = json.dumps({\"inputText\": prompt, \"textGenerationConfig\":\n",
    "                           {\"maxTokenCount\":3000,\"stopSequences\":[],\"temperature\":0,\"topP\":0.9}})\n",
    "        modelId = 'amazon.titan-tg1-large' # change this to use a different version from the model provider\n",
    "        accept = 'application/json'\n",
    "        contentType = 'application/json'\n",
    "\n",
    "        response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "\n",
    "        return response_body.get('results')[0].get('outputText')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc76d7-cea3-40ea-82ed-3b73fee8edc1",
   "metadata": {},
   "source": [
    "1. company strategy:\n",
    "board, company, corporate, governance, management, executive, director, shareholder, global, engagement, vote, term, responsibility, business, team\n",
    "\n",
    "2. green energy:\n",
    "energy, emission, million, renewable, use, project, reduce, carbon, water, billion, power, green, total, gas, source\n",
    "\n",
    "3. customer focus:\n",
    "customer, provide, business, improve, financial, support, investment, service, year, sustainability, nancial, global, include, help, initiative\n",
    "\n",
    "4. support community:\n",
    "community, people, business, support, new, small, income, real, woman, launch, estate, access, customer, uk, include \n",
    "\n",
    "5. ethical investments:\n",
    "investment, climate, company, change, portfolio, risk, responsible, sector, transition, equity, investor, sustainable, business, opportunity, market\n",
    "\n",
    "6. sustainable finance:\n",
    "sustainable, impact, sustainability, asset, management, environmental, social, investing, company, billion, waste, client, datum, investment, provide\n",
    "\n",
    "7. code of conduct:\n",
    "include, policy, information, risk, review, management, investment, company, portfolio, process, environmental, governance, scope, conduct, datum\n",
    "\n",
    "8. strong governance:\n",
    "risk, business, management, environmental, customer, manage, human, social, climate, approach, conduct, page, client, impact, strategic\n",
    "\n",
    "9. value employees:\n",
    "employee, work, people, support, value, client, company, help, include, provide, community, program, diverse, customer, service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42114db4",
   "metadata": {},
   "source": [
    "Now, lets define the prompts to enable our extraction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e08bf3-40aa-4f86-a01a-cfac9826cce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json_from_string(input_string):\n",
    "    pattern = r'\\{.*?\\}|\\[.*?\\]'\n",
    "    match = re.search(pattern, input_string.replace('\\n', ' ').replace('```', ''))\n",
    "    if match:\n",
    "        return json.loads(match.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ad98c",
   "metadata": {
    "id": "605ad98c"
   },
   "source": [
    "Some of the letters are going to be very long for most LLMs to take them as input. So, lets split the large text in a contextaware manner using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7535fa-3f81-49ec-af18-2a05aed14825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True) #downloads the tokenizer model that will help us with context aware of text splitting\n",
    "\n",
    "text = inp_text\n",
    "\n",
    "text_splitter = NLTKTextSplitter()\n",
    "docs = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443f3ba-a4a0-4e91-a0f2-188a1e5d024d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spl=text.split('\\n')\n",
    "docs=[]\n",
    "for i in range(len(spl)//250+1):\n",
    "    docs.append('\\n'.join(spl[i:i+250]))\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93ebb8-7bac-4357-86de-71d6612eee15",
   "metadata": {},
   "source": [
    "## Extract environmental, social and governance achievements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479bb11-d69a-4b5a-8a59-a9bd64ee701b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import Template\n",
    "import json\n",
    "\n",
    "things_achieved_tpl=\"\"\"In this chunk of ESG report from a Company, list out the metrics or things that the company achieved:\n",
    "$ctext\n",
    "Achievements:\n",
    "\"\"\"\n",
    "achievements = []\n",
    "for chunk in docs:\n",
    "    prompt = Template(things_achieved_tpl).substitute(ctext=chunk)\n",
    "    response = call_titan_model(prompt)\n",
    "    if response.strip().lower() != 'n/a':\n",
    "        print(response)\n",
    "        achievements.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf9b137-8d79-4139-a7f8-88004e213011",
   "metadata": {},
   "source": [
    "## Extract environmental metric and value from achievements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381c5cf-ed7e-4439-b0ac-4bc532c54da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_env_achievements_to_metrics = \"\"\"These are the list of achievements extracted from a Company's ESG report. \n",
    "Now, extract only the achievements related to Environment and convert them to a tuple of the environmental metric and its value\n",
    "$ctext\n",
    "Tuples:\n",
    "\"\"\"\n",
    "env_metrics = []\n",
    "prompt = Template(convert_env_achievements_to_metrics).substitute(ctext='\\n'.join(achievements))\n",
    "response = call_titan_model(prompt)\n",
    "if response.strip().lower() != 'n/a':\n",
    "    print(response)\n",
    "    env_metrics.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24e0bb-8080-4fbd-a0b3-6dad31bdb66f",
   "metadata": {},
   "source": [
    "## Extract social metric and value from achievements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8c21b-371e-495d-b9f8-9ffaa065cd35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_social_achievements_to_metrics = \"\"\"These are the list of achievements extracted from a Company's ESG report. \n",
    "Now, extract only the achievements related to Corporate Social Responsiblity and convert them to a tuple of the metric name and its quantitative value. If there is more than one value for a metric, create a new tuple with that value\n",
    "$ctext\n",
    "Tuples:\n",
    "\"\"\"\n",
    "soc_metrics = []\n",
    "prompt = Template(convert_social_achievements_to_metrics).substitute(ctext='\\n'.join(achievements))\n",
    "response = call_titan_model(prompt)\n",
    "if response.strip().lower() != 'n/a':\n",
    "    print(response)\n",
    "    soc_metrics.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38fce71-ae4a-497e-90d6-a39d81d088b0",
   "metadata": {},
   "source": [
    "## Extract governance metric and value from achievements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b677a-71e2-47a8-8e98-3f98bcb3ce71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_governance_achievements_to_metrics = \"\"\"These are the list of achievements extracted from a Company's ESG report. \n",
    "Now, extract only the achievements related to Corporate Governance and convert them to a tuple of the metric name and its quantitative value. If there is more than one value for a metric, create a new tuple with that value\n",
    "$ctext\n",
    "Tuples:\n",
    "\"\"\"\n",
    "gov_metrics = []\n",
    "prompt = Template(convert_governance_achievements_to_metrics).substitute(ctext='\\n'.join(achievements))\n",
    "response = call_titan_model(prompt)\n",
    "if response.strip().lower() != 'n/a':\n",
    "    print(response)\n",
    "    gov_metrics.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd59ace-2290-49b9-9e4d-cd67661d987d",
   "metadata": {},
   "source": [
    "## Extract quantifiable criteria, value and target year for each goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa5d6b-97c3-4bb8-b421-1f34de721390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "planned_goals_tpl=\"\"\"In this chunk of ESG report from a Company, list out the goals that the company is planning in the near future:\n",
    "$ctext\n",
    "Goals:\n",
    "\"\"\"\n",
    "goals = []\n",
    "for chunk in docs:\n",
    "    prompt = Template(planned_goals_tpl).substitute(ctext=chunk)\n",
    "    response = call_titan_model(prompt)\n",
    "    if response.strip().lower() != 'n/a':\n",
    "        print(response)\n",
    "        goals.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feb2a60",
   "metadata": {
    "id": "8feb2a60"
   },
   "source": [
    "## Data Ingestion Cypher Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96efc5",
   "metadata": {
    "id": "0b96efc5"
   },
   "source": [
    "The entities and relationships we got from the LLM have to be transformed to Cypher so we can write them into Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c69170",
   "metadata": {
    "id": "54c69170",
    "tags": []
   },
   "source": [
    "## Data Ingestion\n",
    "You will need a Neo4j instance.  You can deploy that on AWS Marketplace [here](https://aws.amazon.com/marketplace/pp/prodview-akmzjikgawgn4).\n",
    "\n",
    "With that complete, you'll need to install the Neo4j library and set up your database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecea5ff",
   "metadata": {
    "id": "0ecea5ff"
   },
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "\n",
    "# username is neo4j by default\n",
    "username = 'neo4j'\n",
    "\n",
    "# You will need to change these variables\n",
    "connectionUrl = 'foourl'\n",
    "password = 'foopasswd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfa6e8",
   "metadata": {
    "id": "ddbfa6e8"
   },
   "outputs": [],
   "source": [
    "gds = GraphDataScience(\n",
    "    connectionUrl,\n",
    "    auth=(username, password),\n",
    "    )\n",
    "\n",
    "gds.set_database(\"neo4j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a3a58",
   "metadata": {
    "id": "228a3a58"
   },
   "source": [
    "Before loading the data, create constraints as below"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
