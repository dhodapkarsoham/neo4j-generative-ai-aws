{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3d39ab",
   "metadata": {
    "id": "3d3d39ab"
   },
   "source": [
    "# notebook.ipynb\n",
    "This is a sample notebook and web application which shows how Amazon Bedrock and Titan can be used with Neo4j. We will explore how to leverage generative AI to build and consume a knowledge graph in Neo4j.\n",
    "\n",
    "The dataset we're using is from the SEC's EDGAR system.  It was downloaded using [these scripts](https://github.com/neo4j-partners/neo4j-sec-edgar-form13).\n",
    "\n",
    "The dataflow in this demo consists of two parts:\n",
    "1. Ingestion - we read the EDGAR files with Bedrock, extracting entities and relationships from them.  Bedrock then generates Neo4j Cypher that is run against a Neo4j database deployed from AWS Marketplace.\n",
    "2. Consumption - A user inputs natural language into a web UI.  Bedrock converts that to Neo4j Cypher which is run against the database.  This flow allows non technical users to query the database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a9328-f17d-48ae-b72e-c333fb867eb0",
   "metadata": {
    "id": "f17a9328-f17d-48ae-b72e-c333fb867eb0",
    "tags": []
   },
   "source": [
    "## Setup\n",
    "Select the SageMaker Data Science 3.0 image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb2fda-70c8-4733-ac6f-2678e5cbff47",
   "metadata": {
    "id": "87eb2fda-70c8-4733-ac6f-2678e5cbff47"
   },
   "source": [
    "Now, let's install Bedrock libraries. Currently they are in preview. So, you have to download them here and unzip to a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be06b0f-fe29-417f-bc8c-0593eb908577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip uninstall -y botocore3\n",
    "#%pip uninstall -y boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a489800-9ba8-4584-af5f-a266ea14899d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -O /root/bedrock-python-sdk.zip https://preview.documentation.bedrock.aws.dev/Documentation/SDK/bedrock-python-sdk.zip\n",
    "!unzip /root/bedrock-python-sdk.zip -d /root/bedrock-python-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa6ceb0-bcaf-4122-8ab8-c39e682f1698",
   "metadata": {},
   "source": [
    "Make sure the `boto` & `botocore` libs correspond to the right version of your downloaded SDK. And then execute the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54d6af-36c1-4325-bae9-97786a49b003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install /root/bedrock-python-sdk/boto3-1.26.162-py3-none-any.whl\n",
    "%pip install /root/bedrock-python-sdk/botocore-1.29.162-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43720d2e-05cd-49de-bbb9-15c0b10d768b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --user \"langchain>=0.0.237\"\n",
    "%pip install --user nltk\n",
    "%pip install --user graphdatascience\n",
    "%pip install --user pydantic\n",
    "%pip install --user IProgress\n",
    "%pip install --user tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f91036-7018-465f-b4af-8d5523e7ed3a",
   "metadata": {},
   "source": [
    "Now restart the kernel.  That will allow the Python evironment to import the new packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad823ee-84ca-4de3-9b29-4b324ac5b9ae",
   "metadata": {
    "id": "4ad823ee-84ca-4de3-9b29-4b324ac5b9ae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Provide your `SERVICE_NAME` (e.g. `bedrock`) & `REGION_NAME` (e.g. `us-east-1`)\n",
    "SERVICE_NAME = 'bedrock'\n",
    "REGION_NAME = 'us-west-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c5a70c-aee1-462b-953a-4c87a524a111",
   "metadata": {
    "id": "42c5a70c-aee1-462b-953a-4c87a524a111",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "bedrock = boto3.client(\n",
    " service_name=SERVICE_NAME,\n",
    " region_name=REGION_NAME,\n",
    " endpoint_url=f'https://{SERVICE_NAME}.{REGION_NAME}.amazonaws.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e43bb3c",
   "metadata": {
    "id": "4e43bb3c"
   },
   "source": [
    "## Prompt Definition\n",
    "In the upcoming sections, we will extract knowledge adhering to the following schema. This is a very Simplified schema to extract only the information we are interested in. Normally, you will have Domain Experts who come up with an ideal Schema. Neo4j being a schema-flexible database, the schema can be modified later to accomodate new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dfc155-d313-48e5-a5b0-17f6347beff5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Schema:\n",
    "````\n",
    "(:Manager{name:string})-[:OWNS{reportCalendarOrQuarter:string,value:number,sshPrnamt:number,sshPrnamtType:string,investmentDiscretion:string,votingSole:number,votingShared:number,votingNone:number}]->(:Company{nameOfIssuer:string,cusip:string})\n",
    "(:Manager{name:string})-[:HAS_ADDRESS]->(Address{street1:string,street2:string,city:string,stateOrCounty:string,zipCode:string})\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7781a12b",
   "metadata": {
    "id": "7781a12b"
   },
   "source": [
    "To achieve our Extraction goal as per the schema, I am going to chain a series of prompts, each focused on only one task - to extract a specific entity. By this way, you can go for more granular extraction. The prompts I used here can be improved and in production scenario, you should consider running QA on the prompt pipelines to ensure that the extracted information is correct. Also, you should consider a landing and serving zones and ensure only curated data lands the serving zone.\n",
    "\n",
    "Let's go in this order to gather the data in accordance to out data model:\n",
    "1. Extract environmental, social and governance achievements\n",
    "2. Extract quantifiable criteria, value and target year for each goal\n",
    "3. Extract environmental metric and value from achievements\n",
    "4. Extract social metric and value from achievements\n",
    "5. Extract governance metric and value from achievements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7028d309",
   "metadata": {},
   "source": [
    "## Data Preparation and Helper functions\n",
    "Our input source is a `txt` file served from a URL. So, lets write some code to extract and convert the txt to json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27107c1c-a5f0-4c88-8bbd-e3ee94f758aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "inp_text = ''\n",
    "with open('./data/raw_2023-05-15_archives_edgar_data_1000097_0001000097-23-000006.txt') as f:\n",
    "    inp_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a414dc",
   "metadata": {},
   "source": [
    "Now, let's write some helper functions to call Bedrock's Titan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d903cb98-ce84-43bb-b860-71a394604a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_titan_model(prompt):\n",
    "    try:\n",
    "        body = json.dumps({\"inputText\": prompt, \"textGenerationConfig\":\n",
    "                           {\"maxTokenCount\":3000,\"stopSequences\":[],\"temperature\":0,\"topP\":0.9}})\n",
    "        modelId = 'amazon.titan-tg1-large' # change this to use a different version from the model provider\n",
    "        accept = 'application/json'\n",
    "        contentType = 'application/json'\n",
    "\n",
    "        response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "\n",
    "        return response_body.get('results')[0].get('outputText')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42114db4",
   "metadata": {},
   "source": [
    "Now, lets define the prompts to enable our extraction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e08bf3-40aa-4f86-a01a-cfac9826cce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json_from_string(input_string):\n",
    "    pattern = r'\\{.*?\\}|\\[.*?\\]'\n",
    "    match = re.search(pattern, input_string.replace('\\n', ' ').replace('```', ''))\n",
    "    if match:\n",
    "        return json.loads(match.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aab78d-6d6e-4750-96b1-9000456df2e9",
   "metadata": {},
   "source": [
    "The first part of the Input text contains Manager information and the latter is filing info. \n",
    "Lets break them up to avoid LLM token limitations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95a4a73e-e5cc-44e8-ae45-41ac7e689c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parts = inp_text.split('</edgarSubmission>') #splits the text into manager details and filing details\n",
    "manager_info = parts[0]\n",
    "filing_info = parts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e073c852-831b-4fbd-ac44-809840fc743f",
   "metadata": {},
   "source": [
    "Sometimes `filing_info` can be larger text beyond the limits of LLM input length. So, lets split that up to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e7535fa-3f81-49ec-af18-2a05aed14825",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def split_filing_info(s):\n",
    "    splitter = '</infoTable>'\n",
    "    _parts = s.split(splitter)\n",
    "    chunks_of_list = np.array_split(_parts, len(_parts)/15) # max 15 filings per part\n",
    "    chunks_of_str = map(lambda x: splitter.join(x), chunks_of_list)\n",
    "    return list(chunks_of_str)\n",
    "\n",
    "filing_info_chunks = split_filing_info(filing_info)\n",
    "len(filing_info_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93ebb8-7bac-4357-86de-71d6612eee15",
   "metadata": {},
   "source": [
    "## Extract Manager info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f479bb11-d69a-4b5a-8a59-a9bd64ee701b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n</XML>\\n</TEXT>\\n</TYPE>\\n</SEQUENCE>\\n</DOCUMENT>\\n```tabular-data-json\\n{\"rows\": [[\"Street1\", \"152 WEST 57TH STREET\"], [\"Street2\", \"50TH FLOOR\"], [\"City\", \"NEW YORK\"], [\"StateOrCounty\", \"NY\"], [\"ZipCode\", \"10019\"]]}\\n```'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import Template\n",
    "import json\n",
    "\n",
    "mgr_info_tpl=\"\"\"From the text below, extract the following as json. Do not miss any of these information.\n",
    "* \"name\" - The name from the <name> tag under <filingManager> tag\n",
    "* \"street1\" - The manager's street1 address from the <com:street1> tag under <address> tag\n",
    "* \"street2\" - The manager's street2 address from the <com:street2> tag under <address> tag\n",
    "* \"city\" - The manager's city address from the <com:city> tag under <address> tag\n",
    "* \"stateOrCounty\" - The manager's stateOrCounty address from the <com:stateOrCountry> tag under <address> tag\n",
    "* \"zipCode\" - The manager's zipCode from the <com:zipCode> tag under <address> tag\n",
    "\n",
    "Text:\n",
    "$ctext\n",
    "\"\"\"\n",
    "achievements = []\n",
    "prompt = Template(mgr_info_tpl).substitute(ctext=manager_info)\n",
    "response = call_titan_model(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf9b137-8d79-4139-a7f8-88004e213011",
   "metadata": {},
   "source": [
    "## Extract Filing Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0381c5cf-ed7e-4439-b0ac-4bc532c54da6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```tabular-data-json\n",
      "{\"rows\": [[\"nameOfIssuer\", \"ACADEMY SPORTS &amp; OUTDOORS IN\"]]}\n",
      "```\n",
      "```tabular-data-json\n",
      "{\"rows\": [[\"nameOfIssuer\", \"FTAI AVIATION LTD\"], [\"nameOfIssuer\", \"GREAT ELM GROUP INC\"], [\"nameOfIssuer\", \"HAEMONETICS CORP MASS\"], [\"nameOfIssuer\", \"INVESCO EXCH TRADED FD TR II\"], [\"nameOfIssuer\", \"HASBRO INC\"], [\"nameOfIssuer\", \"IVERIC BIO INC\"], [\"nameOfIssuer\", \"JASPER THERAPEUTICS INC\"], [\"nameOfIssuer\", \"LIONS GATE ENTMNT CORP\"], [\"nameOfIssuer\", \"LPL FINL HLDGS INC\"], [\"nameOfIssuer\", \"MOLSON COORS BEVERAGE CO\"], [\"nameOfIssuer\", \"META PLATFORMS INC\"], [\"nameOfIssuer\", \"PALO ALTO NETWORKS INC\"], [\"nameOfIssuer\", \"OSCAR HEALTH INC\"]]}\n",
      "```\n",
      "```tabular-data-json\n",
      "{\"rows\": [[\"titleOfClass\", \"COM\"]]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "filing_info_tpl = \"\"\"From the text below, extract the following as json. Do not miss any of these information.\n",
    "* \"nameOfIssuer\" - The name from the <nameOfIssuer> tag under <filingManager> tag\n",
    "* \"cusip\" - The cusip from the <cusip> tag under <address> tag\n",
    "* \"reportCalendarOrQuarter\" - The reportCalendarOrQuarter from the <reportCalendarOrQuarter> tag under <address> tag\n",
    "* \"value\" - The value from the <value> tag under <address> tag\n",
    "* \"sshPrnamt\" - The sshPrnamt from the <sshPrnamt> tag under <address> tag\n",
    "* \"sshPrnamtType\" - The sshPrnamtType from the <sshPrnamtType> tag under <address> tag\n",
    "* \"investmentDiscretion\" - The investmentDiscretion from the <investmentDiscretion> tag under <address> tag\n",
    "* \"votingSole\" - The votingSole from the <votingSole> tag under <address> tag\n",
    "* \"votingShared\" - The votingShared from the <votingShared> tag under <address> tag\n",
    "* \"votingNone\" - The votingNone from the <votingNone> tag under <address> tag\n",
    "\n",
    "Text:\n",
    "$ctext\n",
    "\"\"\"\n",
    "filings = []\n",
    "for chunk in filing_info_chunks:\n",
    "    prompt = Template(filing_info_tpl).substitute(ctext=chunk)\n",
    "    response = call_titan_model(prompt)\n",
    "    print(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feb2a60",
   "metadata": {
    "id": "8feb2a60"
   },
   "source": [
    "## Data Ingestion Cypher Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96efc5",
   "metadata": {
    "id": "0b96efc5"
   },
   "source": [
    "The entities and relationships we got from the LLM have to be transformed to Cypher so we can write them into Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c69170",
   "metadata": {
    "id": "54c69170",
    "tags": []
   },
   "source": [
    "## Data Ingestion\n",
    "You will need a Neo4j instance.  You can deploy that on AWS Marketplace [here](https://aws.amazon.com/marketplace/pp/prodview-akmzjikgawgn4).\n",
    "\n",
    "With that complete, you'll need to install the Neo4j library and set up your database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecea5ff",
   "metadata": {
    "id": "0ecea5ff"
   },
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "\n",
    "# username is neo4j by default\n",
    "username = 'neo4j'\n",
    "\n",
    "# You will need to change these variables\n",
    "connectionUrl = 'foourl'\n",
    "password = 'foopasswd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfa6e8",
   "metadata": {
    "id": "ddbfa6e8"
   },
   "outputs": [],
   "source": [
    "gds = GraphDataScience(\n",
    "    connectionUrl,\n",
    "    auth=(username, password),\n",
    "    )\n",
    "\n",
    "gds.set_database(\"neo4j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a3a58",
   "metadata": {
    "id": "228a3a58"
   },
   "source": [
    "Before loading the data, create constraints as below"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Base Python 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-base-python-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
